
\section{Installation}

\Css{div.lstlisting{font-family: monospace;
    white-space: nowrap; margin-top:0.5em;
    margin-bottom:0.5em;
    color: blue;}}

\Css{ol li { padding: 0; margin: 0.5em; }}

\subsection{Dependencies}

\begin{itemize}
	\item A Hadoop cluster (we have tested with Hadoop 0.20.2)
	\item Pig (at least version 0.10)
\end{itemize}
%
The following two dependencies are already included in a pre-compiled SeqPig release:
\begin{itemize}
\item Hadoop-BAM (\url{https://sourceforge.net/projects/hadoop-bam/})
\item Seal (\url{http://biodoop-seal.sourceforge.net/})
\end{itemize}

\subsection{Environment variables}
\label{sect:install_env}
\begin{itemize}
\item Set Hadoop-related variables (e.g., {\tt HADOOP\_HOME}) for your
	installation
\item Set {\tt PIG\_HOME} to point to your Pig installation
\end{itemize}

On a Cloudera Hadoop installation with Pig a suitable environment configuration would be:
\begin{lstlisting} 
$ export HADOOP_HOME=/usr/lib/hadoop
$ export PIG_HOME=/usr/lib/pig
\end{lstlisting}

\subsection{Installing a pre-compiled release}

\begin{enumerate}
\item Dowload the latest SeqPig release from \url{https://sourceforge.net/projects/seqpig/}
\item Untar the release into an installation directory of your choice and set the {\tt SEQPIG\_HOME}
  environment variable to point to the installation directory of SeqPig; e.g.,
%
\begin{lstlisting} 
$ tar xvzf seqpig_0.5.tar.gz -C /usr/local/java/
$ export SEQPIG_HOME=/usr/local/java/seqpig 
\end{lstlisting}
%
\item For your convenience, you can add the bin directory to your {\tt PATH}:
%
\begin{lstlisting} 
$ export PATH=${PATH}:${SEQPIG_HOME}/bin
\end{lstlisting}
%
This way, you'll be able to start a SeqPig-enabled Pig shell by running the {\tt
seqpig} command.
\end{enumerate}

\subsection{Instructions for building SeqPig}

\begin{enumerate}
\item Download hadoop-bam from \url{https://sourceforge.net/projects/hadoop-bam/}.
\item Download and build the latest Seal git master version from
 \url{http://biodoop-seal.sourceforge.net/}. Note that this requires setting
 {\tt HADOOP\_BAM} to the installation directory of hadoop-bam.

\item Inside the cloned SeqPig git repository create a
{\tt lib/} subdirectory and copy (or link) the jar files
from hadoop-bam and Seal to this new directory.  The files should be:
\begin{enumerate}
	\item \verb@${HADOOP_BAM}/*.jar@
	\item from the Seal directory, run \verb@ find build/ -name seal.jar@
\end{enumerate}
%
Note: the Picard and Sam jar files are contained in the hadoop-bam release
for convenience.

\item Run {\tt ant} to build {\tt SeqPig.jar}.
\end{enumerate}

Once you've built SeqPig, you can move the directory to a location of your
preference (if on a shared system, perhaps {\tt /usr/local/java/seqpig}, else
even your home directory could be fine).

\subsubsection{Note}
\label{sect:piggybank_note}

Some of the example scripts in this manual (e.g.,
Section~\ref{sect:read_clipping}) require functions from \emph{PiggyBank},
which is a collection of publicly available User-Defined Functions (UDF's)
that are distributed with Pig but may need to be built separately, depending on
your Pig distribution.
For more details see
\url{https://cwiki.apache.org/confluence/display/PIG/PiggyBank}. Verify that
PiggyBank has been compiled by looking for the file {\tt piggybank.jar} under
{\tt \$PIG\_HOME}:
\begin{lstlisting} 
$ find $PIG_HOME -name piggybank.jar
\end{lstlisting}
If PiggyBank hasn't been compiled, go into {\tt
\$PIG\_HOME/contrib/piggybank/java} and run {\tt ant}.

\subsection{Running on Amazon Elastic MapReduce}

Assuming you have started an interactive Pig Job Flow (for example via
the AWS console), you can login into the master node and copy the SeqPig release to the Hadoop
user home directory. Then set both {\tt SEQPIG\_HOME} and {\tt PIG\_HOME}
correctly ({\tt HADOOP\_HOME} should be set by default). Note that the
Pig version installed does not necessarily match the latest Pig release.
The advantage, however, is the ability to use S3 buckets for input and
output.

Consider the following example for starting SeqPig on EMR. In this example we assume that the SeqPig release was installed
into {\tt /home/hadoop/seqpig}.
\begin{lstlisting} 
$ export SEQPIG_HOME=/home/hadoop/seqpig
$ export PIG_HOME=/home/hadoop/.versions/pig-0.9.2
$ /home/hadoop/seqpig/bin/seqpig
\end{lstlisting}

\subsection{Tests}

After building SeqPig it may be a good idea to run tests to verify that
the environment has been set up correctly. When inside the SeqPig directory
execute
\begin{lstlisting} 
$ test/test_all.sh
\end{lstlisting}
By default the tests run Pig in local mode. In order to test Hadoop
mode pass the command line argument {\tt -h}. Note that this test
requires that Hadoop to be set up correctly. It first imports a BAM
file, sorts the reads by coordinate and converts it to SAM for
comparing the results. The test should end with the line
\begin{lstlisting}
TEST: all tests passed
\end{lstlisting}
If you intend to run SeqPig on an Amazon Elastic MapReduce instance, you can
also test input from S3 by providing an S3 path to the file {\tt data/input.bam}:
\begin{lstlisting} 
$ test/test_all.sh -s <s3_path>
\end{lstlisting}
for example:
\begin{lstlisting} 
$ test/test_all.sh -s seqpig/data/input.bam
\end{lstlisting}
where {\tt seqpig} is the name of the S3 bucket.

\subsection{Usage}

\subsubsection{Pig grunt shell for interactive operations}
Assuming that all the environment variables have been set as described in the
previous sections, you can start the SeqPig-enabled ``grunt'' shell by running
%
\begin{lstlisting}
$ seqpig
\end{lstlisting}
%
If you prefer to tun SeqPig in local mode (without Hadoop), which is useful
for debugging scripts, you can start it by running
%
\begin{lstlisting}
$ seqpig -x local
\end{lstlisting}
%
\subsubsection{Starting scripts from the command line for non-interactive use}
Alternatively to using the interactive Pig grunt shell, users can write scripts
that are then submitted to Pig/Hadoop for automated execution. This type of
execution has the advantage of being able to handle parameters; for instance,
one can parametrize input and output files. See the {\tt /scripts} directory
inside the SeqPig distribution and Section \ref{sect:examples} for examples.
